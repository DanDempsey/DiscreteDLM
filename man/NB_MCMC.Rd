% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/NB_MCMC.R
\name{NB_MCMC}
\alias{NB_MCMC}
\title{Negative Binomial Regression via MCMC}
\usage{
NB_MCMC(
  formula,
  data = NULL,
  nsamp = 1000,
  nburn = 1000,
  thin = 1,
  prior_beta_mu = 0,
  prior_beta_sigma = 100,
  prior_gamma_p = 0.5,
  prior_xi_shape = 2,
  prior_xi_scale = 1/50,
  init_beta = 0,
  init_gamma = FALSE,
  init_xi = 1
)
}
\arguments{
\item{formula}{Formula object to set the symbolic description of the model to be fitted.}

\item{data}{Optional dataframe, list or environment containing the model variables.}

\item{nsamp}{The desired sample size from the posterior. Set to 5000 by default.}

\item{nburn}{The number of iterations of the MCMC to be discarded as burn-in. Set to 5000 by default.}

\item{thin}{Thinning factor of the MCMC chain after burn-in. Set to 1 by default (no values discarded after burn-in).}

\item{prior_beta_mu}{Mean of the Gaussian prior for the regression coefficients, beta. Either a vector of length equal to the number of predictors or a single numeric to represent a constant vector.}

\item{prior_beta_sigma}{Covariance matrix of the Gaussian prior for the regression coefficients, beta. Either a square matrix of dimension equal to the number of predictors or a single numeric to represent an isotropic covariance matrix.}

\item{prior_gamma_p}{Probability parameter of the Bernoulli prior for the predictor inclusion parameter, gamma. Either a vector of length equal to the number of predictors or a single numeric, to represent that all predictors have the same prior probability of inclusion. Note that the model must have one predictor included by default; because of this the first value must be equal to 1 if a vector is given.}

\item{prior_xi_shape}{Shape parameter of the Gamma distribution prior for the negative binomial stopping parameter, xi.}

\item{prior_xi_scale}{Scale parameter of the Gamma distribution prior for the negative binomial stopping parameter, xi.}

\item{init_beta}{Initial MCMC values for the beta parameters. Either a vector of length equal to the number of predictors or a single numeric representing the same starting value for each beta component.}

\item{init_gamma}{Initial MCMC values for the gamma parameters. Either a vector of length equal to the number of predictors or a single numeric representing the same starting value for each gamma component. Note that the model must have one predictor included by default; because of this the first value must be equal to 1 if a vector is given.}

\item{init_xi}{Initial MCMC value for xi.}
}
\value{
A list containing the MCMC-derived posterior sample, as well as the data that were used.
}
\description{
Fits a negative binomial regression model using Gibbs sampling and performs Bayesian variable selection.
}
\details{
This function fits a negative binomial regression model via MCMC. Latent variable representation allows for Gibbs sampling of the parameters; see Pillow and Scott (2012) and Zhou et. al. (2012). The algorithm also includes predictor inclusion uncertainty inference (inferred via a Metroplis step) adapted from Holmes and Held (2006). The parameters of interest for this model are the regression slopes (beta), the binary predictor inclusion indicator (gamma) and the negative binomial stopping parameter (xi).

As this is a Bayesian model, priors must be specified. Beta has a Gaussian prior, gamma has a Bernoulli prior, and xi has a Gamma distribution prior.
}
\examples{
X <- dplyr::select( dlnm::chicagoNMMAPS, c('cvd', 'dow', 'temp', 'dptp', 'o3') )
X <- na.omit( X )
arglag <- list( fun = 'bs', df = 4 )
DLM_dat <- dataframe_DLM( X, lag = 40, dynamic_vars =  c('temp', 'dptp', 'o3'), arglag = arglag )
myfit <- NB_MCMC( cvd ~ ., data = DLM_dat )
}
\references{
Jonathan Pillow and James Scott. "Fully Bayesian inference for neural models with negative-binomial spiking." Advances in neural information processing systems 25 (2012).

Mingyuan Zhou, Lingbo Li, David Dunson and Lawrence Carin. "Lognormal and gamma mixed negative binomial regression." Proceedings of the... International Conference on Machine Learning. International Conference on Machine Learning. Vol. 2012. NIH Public Access, 2012.

Chris C. Holmes and Leonhard Held. "Bayesian auxiliary variable models for binary and multinomial regression." (2006): 145-168.
}
\author{
Daniel Dempsey (\href{mailto:dempsed6@tcd.ie}{dempsed6@tcd.ie})
}
